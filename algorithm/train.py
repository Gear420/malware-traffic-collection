#! /usr/bin/env python3
# -*- coding: utf-8 -*-
# @Time    : 2020/9/14 9:22 PM
# @Author  : Gear

import argparse

import myutils
import torch
import numpy as np
import torch.nn as nn
from torch.utils.data import DataLoader, random_split

import model
from data_utils import DatasetFromCSV

timer = myutils.Timer()

# 构建Parser
argparser = argparse.ArgumentParser()
argparser.add_argument('dataset')
argparser.add_argument('--num_epochs',
                       type=int,
                       default=100,
                       help="epochs (default 100)")
argparser.add_argument('--learning_rate',
                       type=float,
                       default=0.0001,
                       help="learning rate (default 0.0001)")
argparser.add_argument('--batch_size',
                       type=int,
                       default=32,
                       help="batch size (default 32)")
argparser.add_argument('-O', default='model.pt', help='path to save model')
args = argparser.parse_args()

dataset = DatasetFromCSV(args.dataset)  # 读取数据


def save():
    torch.save(model.state_dict(), args.O)
    print('Saved to', args.O)


def weigth_init(m):
    if isinstance(m, nn.BatchNorm2d):
        m.weight.data.fill_(1)
        m.bias.data.zero_()
    elif isinstance(m, nn.Linear):
        m.weight.data.normal_(0, 0.01)
        m.bias.data.zero_()


model = model.MLP(dataset.dim, dataset.num_classes)
print("input_size:", dataset.dim)
print("num_classes:", dataset.num_classes)
# gpu
# ------------------------------------------------------------------------
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
model.to(device)
# ------------------------------------------------------------------------
model.apply(weigth_init)
# 损失和优化器
criterion = torch.nn.CrossEntropyLoss()
# criterion = torch.nn.NLLLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)

# Parameters
params = {'batch_size': args.batch_size, 'shuffle': True}

# 分割数据80:20
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size

rand_gen = torch.manual_seed(0)
train_set, test_set = random_split(dataset, (train_size, test_size), rand_gen)
train_loader = DataLoader(train_set, **params, pin_memory=True)
test_loader = DataLoader(test_set, **params, pin_memory=True)

# 保存测试数据
# Keep track of losses for plotting
iter = 0
cur_loss = 0
all_losses = []

# 训练模型
timer.tick()
total_works = train_size * args.num_epochs / args.batch_size
try:
    for epoch in range(1, args.num_epochs + 1):
        for flows, categories in train_loader:
            # gpu
            # -----------------------------------------------------------------------
            flows = flows.to(device)
            categories = categories.to(device)
            # -----------------------------------------------------------------------
            # 正向计算
            outputs = model(flows)
            loss = criterion(outputs, categories)

            # 反向传播和优化
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            loss = loss.item()

            cur_loss += loss

            iter += 1
            if iter % 100 == 0:
                print('{:.0f}% ({}) {:.4f}'.format(iter / total_works * 100,
                                                   timer.tmstr(), loss))
                # Add current loss avg to list of losses
                all_losses.append(cur_loss / 100)
                cur_loss = 0
    print('Saving...')
    save()
except KeyboardInterrupt:
    print("Saving before quit...")
    save()

model.eval()
loss_list = []
with torch.no_grad():
    correct = total = 0
    for flows, categories in test_loader:
        # gpu
        # -----------------------------------------------------------------------
        flows = flows.to(device)
        categories = categories.to(device)
        # -----------------------------------------------------------------------
        outputs = model(flows)
        _, predicted = torch.max(outputs.data, 1)
        total += categories.size(0)
        correct += (predicted == categories).sum().item()

        c_loss = criterion(outputs, categories)
        loss_list.append(c_loss.item())

print('Accuracy: {:.3f}%'.format(100 * correct / total))
print('pre_loss:',np.mean(loss_list))

try:
    from matplotlib import pyplot as plt

    plt.figure()
    plt.plot(all_losses)
    plt.show()
except ImportError:
    pass
